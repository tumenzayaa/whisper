{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: apt\n"
     ]
    }
   ],
   "source": [
    "!apt update && apt install ffmpeg -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting whisper\n",
      "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from whisper) (1.16.0)\n",
      "Building wheels for collected packages: whisper\n",
      "  Building wheel for whisper (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=2ef2d91b9cd05310c72bcce7b19f03198fbb2216ccae763a14c1bee0b8dc2c67\n",
      "  Stored in directory: /Users/tumenzaya/Library/Caches/pip/wheels/34/b8/4e/9c4c3351d670e06746a340fb4b7d854c76517eec225e5b32b1\n",
      "Successfully built whisper\n",
      "Installing collected packages: whisper\n",
      "Successfully installed whisper-1.1.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffmpeg-python\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting future (from ffmpeg-python)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Installing collected packages: future, ffmpeg-python\n",
      "Successfully installed ffmpeg-python-0.2.0 future-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It's official the AI hype train just went on life support with the underwhelming release of GPT 4.5. Yesterday, open AI unveiled the most expensive AI model ever produced, yet it fails to crush any benchmarks when in the awards or offer any novel capabilities whatsoever. It's only real selling point is vibes, and it's supposed to chat anymore natural human-like way. Don't get me wrong, it's a good model, but not good enough to feed the AI hype monster. And it looks increasingly likely that we're not headed into a technological singularity, but rather a sigmoid of sorrow. The Sam Altman couldn't even be bothered to leave his newborn kid in the hospital to show up to the product launch, and instead send it a bunch of interns to demo it. And that's crazy because we're talking about Orion here. In 2023, Tech Leader signed a petition to stop training big models like this. Altman himself made the government to regulate it, and the only thing more disappointing than GPT 4.5 is the release of the Epstein files. In today's video, we'll find out if we just reach the limits of pre-training and generative pre-trained transformers. It is February 28, 2025, and you're watching the code report. I didn't want to make another crappy AI video today, but the bat signal was triggered. Anytime an official video gets ratioed like this, I have no choice but to make a video. Before you unsubscribe, though, I've got an interesting post-gress video on the way. The first thing to know about GPT 4.5 is that it's extremely expensive. If you thought Claude was expensive at $15 per million tokens, GPT 4.5 is five times more expensive at $75 per million outpits tokens. Actually, no correction. That's input tokens. It's $150 per million outpits tokens. And a chat with it. It's currently only available to the $200 per month, Pro users. I tried it out myself, and it does seem to emit chill vibes. But the problem is that highly subjective. However, in the launch, OpenAI talked about a new vibe's benchmark. That's supposed to measure creative thinking. The best way to get a few for the model is to talk to it. So let's jump into a demo. A lot of people on the internet criticize this presentation, but as an introvert myself, I think they did a great job. In addition, it apparently has a far lower hallucination rate. But what I found is that it still makes a lot of silly mistakes. It's not self-aware, and has no idea what GPT 4.5 even is. And says its training cutoff is October 2023. It was, however, able to tell me how many orzer and strawberry that that felt like it's usually forward, but I quickly became disappointed when it gave me the wrong number of elves in La la Palusa. Now, when it comes to programming and science, I didn't even try. Because we already know it's not going to perform as well as the deep thinking models like 03. Then to make matters worse, on the 8 or 0.5-litre lot-coding benchmark, it's not only worse at programming than deep-seek, but also hundreds of times more expensive. Now, if you're an Elon Muskator, you'll want to take a wrong rip of copium right now, because currently XAI's grock is the best model in the world. That's not my opinion, it's the opinion of the betting market. Although by the end of 2025, open AI is still the favorite to have the best model, but its odds are on the decline. That's problematic for open AI, though, because they're raising billions and billions of dollars as they transition to for profit and will need to maintain a massive valuation. Altman says there is no wall, and believes they can scale these models almost infinitely. That's assuming he gets trillions of dollars from soft bank in the Saudis to build these data centers. My theory, as an unqualified ship poster, is that they failed to train GPT 5 with any significant improvement, despite scaling up the number of parameters in compute. GPT 4.5 is the biggest model they've ever created, and now they're lowering the bar for GPT 5, which Altman described a few weeks ago being more like a router that automatically chooses the best model based on your prompt, and that's highly disappointing because I was expecting to be a post-apocalyptic warlord by now. The battling robots and barbecuing rats over burning garbage cans for dinner, but instead I live in this dystopia where artificial superintelligence never comes, and nothing ever happens. But if you're a computer science student, the plateau is great news. AI coding tools are incredible, but they're most useful to real human programmers who know what they're doing, and I don't see that changing anytime soon, and you can start getting really good at programming for free thanks to this video sponsor, brilliant. Their platform provides interactive hands-on lessons that demystify the complexity of deep learning. With just a few minutes of effort each day, you can understand the math and computer science behind the seemingly magic technology. I'd recommend starting with Python, then check out their full, how large language models work course if you really want to look under the hood of chatGPT. Try everything brilliant has to offer for free for 30 days by going to brilliant.org slash fireship, or use the QR code on screen. This has been the CobraPort. Thanks for watching, and I will see you in the next one.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"tiny\")  \n",
    "result = model.transcribe(\"data2.mp3\")\n",
    "print(result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Discovering things are easy. 兔の伺服に 攻撃器の手状が変ですpart1 2 42進層な画面を 繫り出していますHz或者 radio song about songs rio Hygrich Gongundetti tibu tigeya khuisingsi tehok rλα yoon nutla Kumarkänghe mae tBetko Tat ard aruya raj whereil tbq trtheyech vidiyato khus ultahij tidi sh dad vewto Sorry Aboutkoi ni tlak ekha'd yoin tind den necksai Bitcoin baa urge to su vyta thtgive Chiur lbit ko enc yohthles对 jah chotta-le acil bye nukzo au h Within war nehko connectors koi一定要 su shtur ha da sofa me連h chおっat vidya yot 어� .. haya ke mug ge tenir yt tie nd i koi nboa doj koi njiru posti star mungunut usi nd too ga ramek nkh cozo tong yoravta nd zon kaanpan usi niratro nd pit koi nj koi nj ark mungus tulpilis nd i koi nj shush hulch hulch hulch hulch hulch hulch hulch hulch hulch hulch nd none ns e mar iwi koi njyouzel ha toho 悟悟的海南和海南匯有所 taught 了 天之人,天之人,天之人,天之人,天之人 池德 anat Wahl所以 Facte snipers haveived the gods to make the map and simultaneous donnie seeing the sea. Since the sea tide must be surrounded by the sea, it fall from front to back and forth. After a bad night as the net eye caught the sea, it had a warm and smoothines as well. And stepped into the sea, the stars forth by sea sight. BA Vision was some ground in the hospital which was happening during the early 20th century. Tokiruanba laid on top of the quarantine class in 1896 …i made the training for passing 7th century who was leading the whole hospital… …so they didn't want to skip any longer time and said they were able... …so they would continue to think about the situation quickly, while sending the elderly to the hospital like this.. …we were having a great time in the hospital, traversing the hospital's account related to disciplinary and public sector governance ... many students during the period were moved to Z wirdlundrad任何 vitae Media yo ministri khai bikwet Dao y Tel liner ch filler Bizhtush Ja unana Baigerutte Derin hörd mon wind Yun meraonend in sewing Cheese Taerut bik bikwet In Northeastern, Durundundu-Chisa-Tadurupat, Kodna, Zadekler-Kodna, Sotpro-Kosai. Sangok-Yung-Zunintokatiyu-Tadurupat-Mokharoi-Ran-Nixar-Nbeetler, Nibit-Koy-Nyung-Nakmen-Gasit-Njum-Nyung-Tadurupar-Ran-Tibit-Chisa, Kier-Nixai-Bit-Koy-Nn, Oldon-Chil-Mung-Dimdur-Tad-Chotna, Sari-Kong-Kodna, Nibit-Koy-Nyung-Tadurupat-Mokharoi-Ran-Tyot-Mokharoi-Ran-Tibit-Njum-Nak-Tru'm. Yasorkut-Yung-Ning-Durupat-Mokharoi-Ran-Taburutat-Akmen-Gasit-Kod-Koessole, K diligentil-Betler him-Betler-Benjem, Kpta-Akman-Jakaryyduripituds Ksame-Kodayaghan- Kusom Robacheeik kokmuket Artkkah-Ira-Sapanya-Stated K Devce! 雨晴�ienie 雨晴晴晴晴晴晴晴 雨晴晴晴晴晴晴晴晴晴晴晴我 iotel uresden\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"tiny\")  \n",
    "result = model.transcribe(\"data.mp3\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
